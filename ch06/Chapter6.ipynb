{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baf9120f-5c8a-4b6f-91e8-9fce2c764554",
   "metadata": {},
   "source": [
    "# Chapter 6 - Learning Best Practices for Model Evaluation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b87920a-e66d-4dfe-b6bb-b0580ec59667",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b723a3a8-3c93-4da5-a74a-81c3677d17f4",
   "metadata": {},
   "source": [
    "- [Streaming workflows with pipelines](#Streaming-workflows-with-pipelines)\n",
    "    - [Loading the Breast Cancer Wisconsin dataset](#Loading-the-Breast-Cancer-Wisconsin-dataset)\n",
    "    - [Combining transformers and estimators in a pipeline](#Combining-transformers-and-estimatimators-in-a-pipeline)\n",
    "- [Using k-fold cross-validation to asses model performance](#Using-k-fold-cross-validation-to-asses-model-performance)\n",
    "  - [The holdout method](#The-holdout-method)\n",
    "  - [K-fold cross-validation](#K-fold-cross-validation)\n",
    "- [Debugging algorithms with learning and validation curves](#Debugging-algorithms-with-learning-and-validation-curves)\n",
    "  - [Diagnosing bias and variance problems with learning curves](#Diagnosing-bias-and-variance-problems-with-learning-curves)\n",
    "  - [Addressing overfitting and underfitting with validation curves](#Addressing-overfitting-and-underfitting-with-validation-curves)\n",
    "- [Fine-tuning machine learning models via grid search](#Fine-tuning-machine-learning-models-via-grid-search)\n",
    "  - [Tuning hyperparameters via grid search](#Tuning-hyperparameters-via-grid-search)\n",
    "  - [Exploring hyperparameter configurations more widely with randomized search](#Exploring-hyperparameter-configurations-more-widely-with-randomized-search)\n",
    "  - [More resource-efficient hyperparameter search with successive\n",
    "halving](#More-resource-efficient-hyperparameter-search-with-successive-halving)\n",
    "  - [Algorithm selection with nested cross-validation](#Algorithm-selection-with-nested-cross-validation)\n",
    "- [Looking at different performance evaluation metrics](#Looking-at-different-performance-evaluation-metrics)\n",
    "  - [Reading a confusion matrix](#Reading-a-confusion-matrix)\n",
    "  - [Optimizing the precision and recall of a classification model](#Optimizing-the-precision-and-recall-of-a-classification-model)\n",
    "  - [Plotting a receiver operating characteristic](#Plotting-a-receiver-operating-characteristic)\n",
    "  - [The scoring metrics for multiclass classification](#The-scoring-metrics-for-multiclass-classification)\n",
    "- [Dealing with class imbalance](#Dealing-with-class-imbalance)\n",
    "- [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd6966-2bb4-4e9b-9bd3-add15290ee88",
   "metadata": {},
   "source": [
    "# Streaming workflows with pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5de825-5716-450e-a1fa-6eeebfdf7091",
   "metadata": {},
   "source": [
    "## Loading the Breast Cancer Wisconsin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc578f95-05d6-4bd2-8068-d4754ed8d91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9   ...     22     23      24      25      26      27      28      29  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "                 'machine-learning-databases'\n",
    "                 '/breast-cancer-wisconsin/wdbc.data', header=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7caa44dd-5bed-4d01-b74e-9359a7edd7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b21b45-183c-4e23-ba3b-795d0be8c4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df.loc[:, 2:].values\n",
    "y = df.loc[:, 1].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d666719c-8d52-4e12-bad4-17aabce80ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(['M', 'B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8506ca75-742e-4391-bb61-d010f1a47b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d21a28-11aa-4240-bb5c-0a19e6061fe5",
   "metadata": {},
   "source": [
    "## Combining transformers and estimators in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d051d091-497c-453c-8c99-724e033cc4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        PCA(n_components=2),\n",
    "                        LogisticRegression())\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "test_acc = pipe_lr.score(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "106d8ba8-f54d-42db-b744-9fbe926125c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe_tr = make_pipeline(PCA(n_components=2),\n",
    "                        RandomForestClassifier(n_estimators=10,\n",
    "                                               random_state=1,\n",
    "                                               n_jobs=4))\n",
    "pipe_tr.fit(X_train, y_train)\n",
    "y_pred_tr = pipe_tr.predict(X_test)\n",
    "test_acc_tr = pipe_tr.score(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc_tr:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b27d90-918e-4a2f-b95a-642c15cb468c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.956\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=76,\n",
    "                                criterion='gini',\n",
    "                                random_state=1,\n",
    "                                n_jobs=4)\n",
    "forest.fit(X_train, y_train)\n",
    "test_acc_fr = forest.score(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc_fr:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c9cac-3390-43b5-9d23-f6fd87fdc1b3",
   "metadata": {},
   "source": [
    "# Using k-fold cross-validation to asses model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9051d90e-ee04-4326-b964-9d1d79ffeb2a",
   "metadata": {},
   "source": [
    "## The holdout method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35158c01-128f-4e5b-aa8c-341b2526e811",
   "metadata": {},
   "source": [
    "## K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0685787e-082d-4246-84fd-c0b8fc28c694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 01, Class distr.: [256 153], Acc.: 0.935\n",
      "Fold: 02, Class distr.: [256 153], Acc.: 0.935\n",
      "Fold: 03, Class distr.: [256 153], Acc.: 0.957\n",
      "Fold: 04, Class distr.: [256 153], Acc.: 0.957\n",
      "Fold: 05, Class distr.: [256 153], Acc.: 0.935\n",
      "Fold: 06, Class distr.: [257 153], Acc.: 0.956\n",
      "Fold: 07, Class distr.: [257 153], Acc.: 0.978\n",
      "Fold: 08, Class distr.: [257 153], Acc.: 0.933\n",
      "Fold: 09, Class distr.: [257 153], Acc.: 0.956\n",
      "Fold: 10, Class distr.: [257 153], Acc.: 0.956\n",
      "\n",
      "CV accuracy: 0.950 +/- 0.014\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10).split(X_train, y_train)\n",
    "\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    score = pipe_lr.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    \n",
    "    print(f'Fold: {k+1:02d}, '\n",
    "          f'Class distr.: {np.bincount(y_train[train])}, '\n",
    "          f'Acc.: {score:.3f}')\n",
    "    \n",
    "mean_acc = np.mean(scores)\n",
    "std_acc = np.std(scores)\n",
    "print(f'\\nCV accuracy: {mean_acc:.3f} +/- {std_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44650b3a-3ec1-4117-846e-3ade91ee5d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.93478261 0.93478261 0.95652174 0.95652174 0.93478261 0.95555556\n",
      " 0.97777778 0.93333333 0.95555556 0.95555556]\n",
      "CV accuracy: 0.950 +/- 0.014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_lr,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=-1)\n",
    "print(f'CV accuracy scores: {scores}')\n",
    "print(f'CV accuracy: {np.mean(scores):.3f} '\n",
    "      f'+/- {np.std(scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2d842-4098-436c-940c-b38f3ee3515b",
   "metadata": {},
   "source": [
    "### 76/77 estimators seems to be about optimal on the RandomForestClassifier with K-Fold cross-validation using gini. With Entropy that changes to 101/102.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd6b807-10a2-4a2b-943c-6b3182697c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.95652174 0.97826087 0.97826087 0.97826087 0.95652174 0.95555556\n",
      " 0.95555556 0.93333333 1.         0.95555556]\n",
      "CV accuracy: 0.965 +/- 0.018\n"
     ]
    }
   ],
   "source": [
    "scores_f = cross_val_score(estimator=forest,\n",
    "                           X=X_train,\n",
    "                           y=y_train,\n",
    "                           cv=10,\n",
    "                           n_jobs=-1)\n",
    "print(f'CV accuracy scores: {scores_f}')\n",
    "print(f'CV accuracy: {np.mean(scores_f):.3f} '\n",
    "      f'+/- {np.std(scores_f):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "558ab8de-64ba-4a1d-944f-ad4f0ce5ce38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 01, Class distr.: [256 153], Acc.: 0.957\n",
      "Fold: 02, Class distr.: [256 153], Acc.: 0.978\n",
      "Fold: 03, Class distr.: [256 153], Acc.: 0.978\n",
      "Fold: 04, Class distr.: [256 153], Acc.: 0.978\n",
      "Fold: 05, Class distr.: [256 153], Acc.: 0.957\n",
      "Fold: 06, Class distr.: [257 153], Acc.: 0.956\n",
      "Fold: 07, Class distr.: [257 153], Acc.: 0.956\n",
      "Fold: 08, Class distr.: [257 153], Acc.: 0.933\n",
      "Fold: 09, Class distr.: [257 153], Acc.: 1.000\n",
      "Fold: 10, Class distr.: [257 153], Acc.: 0.956\n",
      "\n",
      "CV accuracy: 0.965 +/- 0.018\n"
     ]
    }
   ],
   "source": [
    "kfold_f = StratifiedKFold(n_splits=10).split(X_train, y_train)\n",
    "\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold_f):\n",
    "    forest.fit(X_train[train], y_train[train])\n",
    "    score = forest.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    \n",
    "    print(f'Fold: {k+1:02d}, '\n",
    "          f'Class distr.: {np.bincount(y_train[train])}, '\n",
    "          f'Acc.: {score:.3f}')\n",
    "    \n",
    "mean_acc = np.mean(scores)\n",
    "std_acc = np.std(scores)\n",
    "print(f'\\nCV accuracy: {mean_acc:.3f} +/- {std_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115b619-7eca-4a94-a2cb-84983c52615f",
   "metadata": {},
   "source": [
    "# Debugging algorithms with learning and validation curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4658ff74-3ae2-4baa-91ef-49c991013d8b",
   "metadata": {},
   "source": [
    "## Diagnosing bias and variance problems with learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805eaa06-f832-4b4a-84fc-00e57945b36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bdc7e61-7976-4940-93ba-14bada5d1d9e",
   "metadata": {},
   "source": [
    "## Addressing overfitting and underfitting with validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487d78ad-f644-4479-970f-60d8f3cdff4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
